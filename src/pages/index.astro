---
import BaseLayout from "../layouts/BaseLayout.astro";
import HorizontalCard from "../components/HorizontalCard.astro";
import { getCollection } from "astro:content";
import createSlug from "../lib/createSlug"

const posts = (await getCollection("blog")).sort((a, b) => b.data.pubDate.valueOf() - a.data.pubDate.valueOf());

const last_posts = posts.slice(0, 3);
---

<BaseLayout sideBarActiveItemID="home">
  <div class="flex flex-col md:flex-row items-center justify-between bg-[#f7f9fb] text-black px-6 py-12 rounded-lg shadow-md">
  <!-- Text Section -->
  <div class="md:w-2/3">
    <div class="text-xl mb-2">Hey there ðŸ‘‹</div>
    <div class="text-5xl font-bold mb-3">I'm Hai Dang Kieu</div>
    <div class="text-2xl font-semibold mb-4">PhD student in Computer Science at VinUniversity</div>
    <ul class="list-disc list-inside text-lg space-y-1">
      <li>ðŸŽ¯ Recommender Systems (News, Sequential, Multimodal)</li>
      <li>ðŸ§  Graph Neural Networks & Knowledge Graphs</li>
      <li>ðŸ“š Generative Models (LLMs, Prompting)</li>
    </ul>
  </div>

  <!-- Image Section -->
  <div class="md:w-1/3 mt-8 md:mt-0 flex justify-center">
    <img src="/logo2.png" alt="VinUniversity Logo" class="max-w-[250px] h-auto" />
  </div>
</div>


<div class="mt-16">
  <div class="text-3xl w-full font-bold mb-2">My last Publication {"</>"}</div>
</div>

  <HorizontalCard
    title="Enhancing News Recommendation with Hierarchical LLM Prompting"
    img="/Picture3.png"
    desc="Personalized news recommendation systems often struggle to effectively capture the complexity of user preferences, as they rely heavily on shallow representations, such as article titles and abstracts. To address this problem, we introduce a novel method, namely PNR-LLM, for Large Language Models for Personalized News Recommendation. Specifically, PNR-LLM harnesses the generation capabilities of LLMs to enrich news titles and abstracts, and consequently improves recommendation quality. PNR-LLM contains a novel module, News Enrichment via LLMs, which generates deeper semantic information and relevant entities from articles, transforming shallow contents into richer representations. We further propose an attention mechanism to aggregate enriched semantic- and entity-level data, forming unified user and news embeddings that reveal a more accurate user-news match"
    url="https://dl.acm.org/doi/10.1145/3701716.3735085"
    badge="WWW2025"
    badgeCL="bg-green-500 text-white"
  />
  <div class="divider my-0"></div>
  <HorizontalCard
    title="Keyword-driven Retrieval-Augmented Large Language Models for Cold-start User Recommendations"
    img="/kalm4rec.png"
    desc="Recent advancements in Large Language Models (LLMs) have shown significant potential in enhancing recommender systems. However, addressing the cold-start recommendation problem, where users lack historical data, remains a considerable challenge. In this paper, we introduce KALM4Rec (Keyword-driven Retrieval-Augmented Large Language Models for Cold-start User Recommendations), a novel framework specifically designed to tackle this problem by requiring only a few input keywords from users in a practical scenario of cold-start user recommendations. KALM4Rec operates in two main stages: candidates retrieval and LLM-based candidates re-ranking. In the first stage, keyword-driven retrieval models are used to identify potential candidates, addressing LLMs' limitations in processing extensive tokens and reducing the risk of generating misleading information. In the second stage, we employ â€¦"
    url="https://dl.acm.org/doi/abs/10.1145/3701716.3717855"
    badge="LLM4Ecommerce WWW2025"
    badgeCL="bg-green-500 text-white"
  />
  <div class="divider my-0"></div>
  <HorizontalCard
    title="Mi-CGA: Cross-modal Graph Attention Network for robust emotion recognition in the presence of incomplete modalities"
    img="/graph.jpg"
    desc="Multimodal Emotion Recognition in Conversation (Multimodal ERC) is crucial for understanding human communication across various applications. However, the challenge of missing modalities impedes the development of robust models. Existing approaches often overlook scenarios where multiple modalities are absent simultaneously and fail to explore deep semantic interactions between modalities. Additionally, learning high-dimensional interactive features from limited samples is challenging due to missing data. This paper proposes Mi-CGA, a framework tailored for incomplete multimodal learning in conversational contexts. Mi-CGA comprises two main components: Incomplete Multimodal Representation (IMR) and Cross-modal Graph Attention Network (CGA-Net). IMR simulates incomplete modalities, while CGA-Net extracts rich information from conversational graphs. CGA-Net consists of three key â€¦"
    url=""
    badge="NeuroComputing"
    badgeCL="bg-green-500 text-white"
  />
</BaseLayout>

